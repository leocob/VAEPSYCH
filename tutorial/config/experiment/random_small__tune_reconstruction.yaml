# @package _global_

# Define the default configuration for the data and task (model and training)

defaults:
  - override /data: random_small
  - override /task: tune_model_reconstruction

# Configure which hyperarameters to vary
# This will run and log the metrics of 12 models (combination of 3 hyperparams
# with 2-3 levels: 2 * 2 * 3)

# Any field defined in the task configuration can be configured below.

hydra:
  mode: MULTIRUN
  sweeper:
    params:
      task.batch_size: 10
      # task.model.num_hidden: "[100,150],[220, 440]" # doesn't work
      # task.model.num_hidden: "[[100,150]],[[220, 440]]" # doesn't work
      # task.model.num_hidden: "[[100],[150]],[[220], [440]]" # doesn't work
      # task.model.num_hidden: "[150],[300],[450],[600],[800]" # this is what I used on genomeDK

      # task.model.num_hidden: "[200, 200]" # doesn't work
      # task.model.num_hidden: "[[200, 200]]" # doesn't work
      # task.model.num_hidden: "[500]"
      task.training_loop.num_epochs: 10
      task.model.num_latent: 3
      task.training_loop.beta: 0.0001
      task.training_loop.num_hidden: "[100,150],[220,440]" # doesn't work
      # task.training_loop.num_hidden: "[[100,150]],[[220, 440]]" # doesn't work
      # task.training_loop.num_hidden: "[[100],[150]],[[220], [440]]" # doesn't work
      # task.training_loop.num_hidden: "[150],[300],[450],[600],[800]" # this is what I used on genomeDK

      # task.training_loop.num_hidden: "[200, 200]" # doesn't work
      # task.training_loop.num_hidden: "[[200, 200]]" # doesn't work
